# fetch/run_scrapers.py

import json
from fetch import ifyoucould, unjobs, workable, linkedin, ziprecruiter

def fetch_jobs(job_location_pairs):
    print(f"\n‚è≥ Running job scrapers for {len(job_location_pairs)} job title + location combinations...")

    jobs = {
        "linkedin": [],
        "ifyoucould": [],
        "unjobs": [],
        # "ziprecruiter": [],
        # "workable": [],
    }

    # üîÅ Run LinkedIn, UNJobs per search pair
    for job_title, location in job_location_pairs:
        print(f"üîç Scraping for: '{job_title}' in '{location}'...")

        # Fetch and validate LinkedIn jobs
        linkedin_results = linkedin.fetch_linkedin_jobs(job_title, location)
        for job in linkedin_results:
            if job.get('source') != 'linkedin':
                print(f"‚ö†Ô∏è LinkedIn job missing correct source: {job.get('title')}")
                job['source'] = 'linkedin'
        jobs["linkedin"].extend(linkedin_results)
        
        # Fetch and validate UN jobs
        un_results = unjobs.fetch_unjobs_parallel([job_title], [location])
        for job in un_results:
            if job.get('source') != 'unjobs':
                print(f"‚ö†Ô∏è UN job missing correct source: {job.get('title')}")
                job['source'] = 'unjobs'
        jobs["unjobs"].extend(un_results)

        # # Uncomment to enable ZipRecruiter
        # zip_results = ziprecruiter.fetch_ziprecruiter_jobs(job_title, location)
        # for job in zip_results:
        #     if job.get('source') != 'ziprecruiter':
        #         print(f"‚ö†Ô∏è ZipRecruiter job missing correct source: {job.get('title')}")
        #         job['source'] = 'ziprecruiter'
        # jobs["ziprecruiter"].extend(zip_results)

        # # Uncomment to enable Workable
        # workable_results = workable.fetch_workable_jobs([job_title], [location])
        # for job in workable_results:
        #     if job.get('source') != 'workable':
        #         print(f"‚ö†Ô∏è Workable job missing correct source: {job.get('title')}")
        #         job['source'] = 'workable'
        # jobs["workable"].extend(workable_results)

    # ‚úÖ Fetch all IfYouCould jobs ONCE
    print("üì• Collecting all If You Could jobs in one scrape...")
    all_ifyoucould_jobs = ifyoucould.fetch_ifyoucould_jobs()

    # üîç Filter and ensure source is set
    for job_title, location in job_location_pairs:
        for job in all_ifyoucould_jobs:
            if job_title.lower() in job["title"].lower() and location.lower() in job["location"].lower():
                job['source'] = 'ifyoucould'  # Ensure source is set
                jobs["ifyoucould"].append(job)

    # Summary with validation
    total_jobs = sum(len(jobs[source]) for source in jobs)
    print(f"‚úÖ Completed scraping. Found {total_jobs} total jobs:")
    for source, job_list in jobs.items():
        print(f"  - {source}: {len(job_list)} jobs")
        # Validate all jobs have correct source
        mismatched = [j for j in job_list if j.get('source') != source]
        if mismatched:
            print(f"    ‚ö†Ô∏è WARNING: {len(mismatched)} jobs have incorrect source!")

    return jobs

def run_scrapers(job_location_pairs):
    return fetch_jobs(job_location_pairs)